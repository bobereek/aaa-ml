# AAA ML: Предсказание весогабаритов товара по карточке товара

## Описание задачи

Задача заключается в предсказании четырех величин: веса, высоты, ширины и длины товара на основе данных из объявления.

**Тренировочный набор данных (`train.parquet`) содержит следующие признаки:**

* `item_id` — уникальный ID товара;
* `order_date` — дата оформления заказа;
* `item_condition` — состояние товара;
* `item_price` — цена, ₽;
* `category_name`, `subcategory_name`, `microcat_name` — иерархия категорий (уровни 1, 2, 3);
* `seller_id`, `buyer_id` — ID продавца и покупателя;
* `title`, `description` — заголовок и описание объявления;
* `image_name` — имя файла изображения (соответствует объекту в архиве);
* **Таргеты:** `real_weight` (кг), `real_height` (см), `real_width` (см), `real_length` (см).

**Тестовая выборка (`test.parquet`)** содержит те же признаки, но без целевых переменных (таргетов).

В качестве метрики качества используется **Macro Log-MAE**. Рассчитывается MAE в лог-шкале для каждого таргета, после чего значения усредняются:

$$ Score = \frac{1}{4} \sum_{t \in \{weight, height, length, width\}} \frac{1}{N} \sum_{i=1}^{N} | \log(1+y_{i,t}) - \log(1+\hat{y}_{i,t}) | $$

где $y_{i,t}$ – истинное значение, а $\hat{y}_{i,t}$ – предсказание.

## Описание решения

### EDA

Я начал с изучения данных: посмотрел на пропуски, выбросы в разрезе микрокатегорий товаров, изучил таргеты.

Я задумался над тем, что продавцы могут по-разному интерпретировать Длину, Ширину и Высоту, и если бы каждый продавец указывал измерения в разнобой (ширину вместо высоты и наоборот), то задача бы сильно усложнилась. Поэтому я предположил, что измерения отсортированы и Длина <= Ширина <= Высота. Я посчитал среднее таргетов по микрокатегориям и сравнил его со средними упорядоченными измерениями min, mid и max, и оказалось, что они совпадают. Таким образом, гипотеза подтвердилась.

Выяснив, что данные содержат выбросы, я задумался над тем, как правильно их обработать. Ведь если просто удалять строки, в которых хотя бы одно измерение является выбросом, мы теряем данные для обучения других таргетов этого товара (если высота - выброс, то длина, ширина и вес могут использоваться в обучении). Так я решил обучать модели для предсказания каждого таргета независимо друг от друга.

Далее я перешел к тексту и соединил название товара ('title') и его описание ('description') в один признак 'text' и базово отформатировал его. При обработке текстовых данных я подумал, что можно попытаться извлечь из описания товаров, так как продавец сам уже мог написать его размеры и это стало бы отличной подсказкой для модели. Я написал функции использующие регулярные выражения и постарался учесть случаи различных единиц измерения, а там где ничего извлечь не удалось заполнял -1.

Прежде чем перейти к обучению моделей, я логарифмировал таргеты, для того чтобы они соответствовали метрике качества, и обучал именно на логарифмах.

В качестве бейзлайна я зафиксировал средние значения лог-таргетов по микрокатегориям и добавил их в качестве фичей в датасет (посчитал средние на train сплите, и добавил их в val и test).
**Baseline Score:** 0.387303.

### CatBoost

В качестве первой модели я решил использовать CatBoost, так как он из коробки отлично работает с категориальными фичами и текстом, обработку изображений оставил на потом. Так я получил скор **0.34082**.

Дальше я перешел к обработке изображений. Я решил получить эмбеддинги при помощи модели EfficientNet_v2_S с весами от ImageNet1K. Для этого я заменил ее последний блок (классификатор) на тождественное преобразование, прогнал через нее все изображения и сохранил в файл, чтобы быстрее и удобнее повторно их использовать. Также я посчитал соотношение сторон изображений, так как при обработке моделью они ресайзились к квадрату 384х384 и эта информация теряется, хотя она может быть крайне полезна для предсказания длины и ширины. К эмбеддингам я решил применить PCA, чтобы выделить самые важные признаки и сократить их количество с 1280 до 96, тем самым еще и сократил время обучения и использование памяти.

С добавлением данных изображений скор чуть улучшился до **0.33491**. Собрав метрики по каждому таргету я заметил, что хуже всего модель справляется с высотой, но это неудивительно, так как тяжело предсказать глубину объекта по 2D изображению.

Изучив влияние фичей на предсказания модели, стало очевидно что самыми полезными были текст и средний лог-таргет по микрокатегории. Эмбеддинги изображений также имели неплохой вклад. А например извлеченные в ручную признаки абсолютно не помогали модели. Видимо CatBoost и без моей помощи доставал их из текста.

Ради интереса я попробовал обучить CatBoost на предсказание сразу 4 таргетов, но скор был хуже (**0.34225**). Независимый подход позволил бустингу лучше находить зависимости для каждого таргета в отдельности.

### NN

Поэкспериментировав с CatBoost, я решил использовать нейронную сеть. Это было интересно, так как необходимо было работать с каждым видом фичей (числовые, категориальные, текстовые и эмбеддинги изображений) по отдельности.

Я подготовил данные (стандартизировал числовые фичи, закодировал при помощи LabelEncoding категориальные, получил текстовые эмбеддинги) и написал архитектуру сети. Для получения текстовых эмбеддингов я решил использовать RuBERT_v2_tiny, он дал существенный прирост в качестве по сравнению с ручным кодированием и добавлением Embedding слоя в сеть. Для начала я обучил сеть, которая предсказывает все 4 таргета на последнем слое и получил отличный прирост качества по сравнению с CatBoost, скор составил **0.32792**.

Далее я решил обучить 4 сети для независимого предсказания таргетов, в надежде, что так же как и в ситуации с CatBoost. Но улучшения на val выборке оказались совсем незначительны (**0.327573**).

### Итог

После всей проделанной работы, долгого подбора параметров и попыток улучшить модели, лучший тестовый скор на Stepik показал Multi NN подход.
**Final Score: 0.318857**.

#### Данные моэно найти тут: <https://disk.360.yandex.ru/d/48VwJNiITMyrEg>
